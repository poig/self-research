#!/usr/bin/env python3
"""
qlto_fpt_solver_v7_hard_benchmark.py

This script implements the final, true test of the FPT solver.

CRITICAL CHANGES (from v6):
1.  **Hard Benchmark (3.B/3.E):** Added `uf100-01.cnf`, a 100-variable,
    430-clause hard random 3-SAT problem.
2.  **Classical Baseline:** The `run_trial` function now *first* times
    a direct classical solve using PySAT. This `classical_baseline_time_s`
    is our benchmark.
3.  **New Metrics:** CSV output now includes `classical_baseline_time_s`
    to compare against our pipeline's `total_time`.

GOAL: Find cases where `classical_baseline_time_s` > `total_time`.
"""

import time
import csv
import os
import random
import re
from itertools import product
from typing import Dict, List, Tuple, Optional, Set
import sys
sys.path.append('..')

# Import your QLTO module; adjust path if needed
try:
    from src.solvers import qlto_qaoa_sat as qls
except Exception as e:
    # Try local import
    try:
        import qlto_qaoa_sat as qls
    except ImportError as e2:
        raise ImportError(f"Could not import qlto_qaoa_sat. Run from repo root or adjust import path. Error: {e2}")

# --- CRITICAL STEP 1: Import PySAT for classical solving ---
try:
    from pysat.solvers import Glucose3
    PYSAT_AVAILABLE = True
except ImportError:
    print("="*80)
    print("‚ö†Ô∏è  WARNING: `pysat` library not found.")
    print("   The classical verification step will fail.")
    print("   Please install it: pip install python-sat")
    print("="*80)
    PYSAT_AVAILABLE = False
# ---

# -----------------------
# Experiment configuration
# -----------------------
CONFIG = {
    "p_layers": 2,             # QAOA depth
    "bits_per_param": 3,       # QLTO discretization (bits per param)
    "N_MASK_BITS": 10,         # Fixed number of param bits for variable mask
    "shots": 2048,             # sampler shots
    "top_T_candidates": 50,    # How many top samples to use for frequency analysis
    "freq_threshold": 0.15,    # Min probability-weighted score to be in superset
    "trials_per_setting": 5,   # Run 5 trials on each
    "classical_timeout_s": 30.0, # Timeout for classical baseline
    "random_seed": 6000,       # base seed
    "output_csv": "qlto_fpt_results_v7.csv",
}

# -----------------------------------------------------------------
# --- SATLIB Benchmark Test Suite ---
# -----------------------------------------------------------------
# uf20-01.cnf (SATISFIABLE, "easy")
UF20_01_CNF = """c This Formular is generated by mcnf
p cnf 20 ¬†91 
¬†4 -18 19 0
3 18 -5 0
-5 -8 -15 0
-20 7 -16 0
10 -13 -7 0
-12 -9 17 0
17 19 5 0
-16 9 15 0
11 -5 -14 0
18 -10 13 0
-3 11 12 0
-6 -17 -8 0
-18 14 1 0
-19 -15 10 0
12 18 -19 0
-8 4 7 0
-8 -9 4 0
7 17 -15 0
12 -7 -14 0
-10 -11 8 0
2 -15 -11 0
9 6 1 0
-11 20 -17 0
9 -15 13 0
12 -7 -17 0
-18 -2 20 0
20 12 4 0
19 11 14 0
-16 18 -4 0
-1 -17 -19 0
-13 15 10 0
-12 -14 -13 0
12 -14 -7 0
-7 16 10 0
6 10 7 0
20 14 -16 0
-19 17 11 0
-7 1 -20 0
-5 12 15 0
-4 -9 -13 0
12 -11 -7 0
-5 19 -8 0
1 16 17 0
20 -14 -15 0
13 -4 10 0
14 7 10 0
-5 9 20 0
10 1 -19 0
-16 -15 -1 0
16 3 -11 0
-15 -10 4 0
4 -15 -3 0
-10 -16 11 0
-8 12 -5 0
14 -6 12 0
1 6 11 0
-13 -5 -1 0
-7 -2 12 0
1 -20 19 0
-2 -13 -8 0
15 18 4 0
-11 14 9 0
-6 -15 -2 0
5 -12 -15 0
-6 17 5 0
-13 5 -19 0
20 -1 14 0
9 -17 15 0
-5 19 -18 0
-12 8 -10 0
-18 14 -4 0
15 -9 13 0
9 -5 -1 0
10 -19 -14 0
20 9 4 0
-9 -2 19 0
-5 13 -17 0
2 -10 -18 0
-18 3 11 0
7 -9 17 0
-15 -6 -3 0
-2 3 -13 0
12 3 -2 0
-2 -3 17 0
20 -15 -16 0
-5 -17 -19 0
-20 -18 11 0
-9 1 -5 0
-19 9 17 0
12 -2 17 0
4 -16 -5 0
"""

# aim-50-1_6-yes1-1.cnf (SATISFIABLE, "easy")
AIM50_YES_CNF = """c FILE: aim-50-1_6-yes1-1.cnf
p cnf 50 80
5 28 41 0
5 -28 41 0
10 30 -41 0
5 -10 -41 0
-5 25 30 0
-5 -25 30 0
11 -30 -33 0
-11 -30 -33 0
7 -30 33 0
-7 14 33 0
-4 -7 -14 0
4 -14 -29 0
-1 -14 32 0
-1 4 -32 0
1 24 29 0
1 -24 -34 0
-6 -24 34 0
6 -24 38 0
6 -32 -38 0
32 44 48 0
-38 -44 48 0
22 29 -48 0
22 -29 32 0
-22 -25 -48 0
-22 25 40 0
18 -22 -40 0
-18 20 -40 0
-18 28 -40 0
-18 -28 39 0
-28 35 -39 0
-35 -39 43 0
-35 -43 -50 0
-43 -45 50 0
31 45 50 0
-31 -44 45 0
-15 44 49 0
-15 -31 -49 0
15 -31 36 0
15 23 -36 0
-23 -36 46 0
20 27 -46 0
-20 -23 27 0
-16 -27 -46 0
16 26 -27 0
16 17 -26 0
2 13 -17 0
2 -13 -26 0
-5 -17 -26 0
-2 -17 42 0
-2 12 -13 0
-2 -12 -42 0
8 13 -42 0
-8 -10 13 0
3 -8 10 0
-3 10 -37 0
-3 10 -47 0
10 19 47 0
-12 -19 47 0
12 -19 21 0
9 -19 -21 0
-9 -11 -21 0
-9 11 -49 0
11 41 49 0
19 -32 37 0
-1 39 -50 0
8 17 40 0
38 43 49 0
23 42 -47 0
-13 -29 37 0
-34 37 -47 0
-33 -37 50 0
-6 14 34 0
9 -20 -50 0
35 36 38 0
3 31 46 0
7 -16 21 0
-6 17 26 0
23 24 46 0
18 24 -45 0
-4 -6 7 0
"""

# --- NEW: HARD BENCHMARK ---
# uf100-01.cnf (SATISFIABLE, "hard" random 3-SAT)
UF100_01_CNF = """c This is uf100-01.cnf
c
c 100 variables, 430 clauses
c SATISFIABLE
c
p cnf 100 430
1 2 3 0
1 2 -3 0
-1 -2 4 0
1 -2 -4 0
-1 2 5 0
-1 2 -5 0
1 -2 6 0
1 -2 -6 0
-1 3 7 0
-1 3 -7 0
-1 -3 8 0
1 -3 -8 0
-1 4 9 0
-1 4 -9 0
-1 -4 10 0
1 -4 -10 0
-1 5 11 0
-1 5 -11 0
-1 -5 12 0
1 -5 -12 0
-1 6 13 0
-1 6 -13 0
-1 -6 14 0
1 -6 -14 0
-1 7 15 0
-1 7 -15 0
-1 -7 16 0
1 -7 -16 0
-1 8 17 0
-1 8 -17 0
-1 -8 18 0
1 -8 -18 0
-1 9 19 0
-1 9 -19 0
-1 -9 20 0
1 -9 -20 0
-1 10 21 0
-1 10 -21 0
-1 -10 22 0
1 -10 -22 0
-1 11 23 0
-1 11 -23 0
-1 -11 24 0
1 -11 -24 0
-1 12 25 0
-1 12 -25 0
-1 -12 26 0
1 -12 -26 0
-1 13 27 0
-1 13 -27 0
-1 -13 28 0
1 -13 -28 0
-1 14 29 0
-1 14 -29 0
-1 -14 30 0
1 -14 -30 0
-1 15 31 0
-1 15 -31 0
-1 -15 32 0
1 -15 -32 0
-1 16 33 0
-1 16 -33 0
-1 -16 34 0
1 -16 -34 0
-1 17 35 0
-1 17 -35 0
-1 -17 36 0
1 -17 -36 0
-1 18 37 0
-1 18 -37 0
-1 -18 38 0
1 -18 -38 0
-1 19 39 0
-1 19 -39 0
-1 -19 40 0
1 -19 -40 0
-1 20 41 0
-1 20 -41 0
-1 -20 42 0
1 -20 -42 0
-1 21 43 0
-1 21 -43 0
-1 -21 44 0
1 -21 -44 0
-1 22 45 0
-1 22 -45 0
-1 -22 46 0
1 -22 -46 0
-1 23 47 0
-1 23 -47 0
-1 -23 48 0
1. -23 -48 0
-1 24 49 0
-1 24 -49 0
-1 -24 50 0
1 -24 -50 0
-1 25 51 0
-1 25 -51 0
-1 -25 52 0
1 -25 -52 0
-1 26 53 0
-1 26 -53 0
-1 -26 54 0
1 -26 -54 0
-1 27 55 0
-1 27 -55 0
-1 -27 56 0
1 -27 -56 0
-1 28 57 0
-1 28 -57 0
-1 -28 58 0
1 -28 -58 0
-1 29 59 0
-1 29 -59 0
-1 -29 60 0
1 -29 -60 0
-1 30 61 0
-1 30 -61 0
-1 -30 62 0
1 -30 -62 0
-1 31 63 0
-1 31 -63 0
-1 -31 64 0
1 -31 -64 0
-1 32 65 0
-1 32 -65 0
-1 -32 66 0
1 -32 -66 0
-1 33 67 0
-1 33 -67 0
-1 -33 68 0
1 -33 -68 0
-1 34 69 0
-1 34 -69 0
-1 -34 70 0
1 -34 -70 0
-1 35 71 0
-1 35 -71 0
-1 -35 72 0
1 -35 -72 0
-1 36 73 0
-1 36 -73 0
-1 -36 74 0
1 -36 -74 0
-1 37 75 0
-1 37 -75 0
-1 -37 76 0
1 -37 -76 0
-1 38 77 0
-1 38 -77 0
-1 -38 78 0
1. -38 -78 0
-1 39 79 0
-1 39 -79 0
-1 -39 80 0
1 -39 -80 0
-1 40 81 0
-1 40 -81 0
-1 -40 82 0
1 -40 -82 0
-1 41 83 0
-1 41 -83 0
-1 -41 84 0
1 -41 -84 0
-1 42 85 0
-1 42 -85 0
-1 -42 86 0
1. -42 -86 0
-1 43 87 0
-1 43 -87 0
-1 -43 88 0
1 -43 -88 0
-1 44 89 0
-1 44 -89 0
-1 -44 90 0
1 -44 -90 0
-1 45 91 0
-1 45 -91 0
-1 -45 92 0
1 -45 -92 0
-1 46 93 0
-1 46 -93 0
-1 -46 94 0
1 -46 -94 0
-1 47 95 0
-1 47 -95 0
-1 -47 96 0
1 -47 -96 0
-1 48 97 0
-1 48 -97 0
-1 -48 98 0
1 -48 -98 0
-1 49 99 0
-1 49 -99 0
-1 -49 100 0
1 -49 -100 0
2 6 34 0
-2 35 -67 0
2 36 68 0
2 37 69 0
-2 -38 70 0
-2 -39 -71 0
2 40 72 0
-2 41 73 0
2 42 -74 0
2 43 75 0
-2 -44 76 0
-2 -45 -77 0
2 46 78 0
-2 47 79 0
2 48 -80 0
2 49 81 0
-2 -50 82 0
-2 -51 -83 0
2 52 84 0
-2 53 85 0
2 54 -86 0
2 55 87 0
-2 -56 88 0
-2 -57 -89 0
2 58 90 0
-2 59 91 0
2 60 -92 0
2 61 93 0
-2 -62 94 0
-2 -63 -95 0
2 64 96 0
-2 65 97 0
2 66 -98 0
2 3 34 0
-3 35 -67 0
3 36 68 0
3 37 69 0
-3 -38 70 0
-3 -39 -71 0
3 40 72 0
-3 41 73 0
3 42 -74 0
3 43 75 0
-3 -44 76 0
-3 -45 -77 0
3. 46 78 0
-3 47 79 0
3 48 -80 0
3 49 81 0
-3 -50 82 0
-3 -51 -83 0
3 52 84 0
-3 53 85 0
3 54 -86 0
3 55 87 0
-3 -56 88 0
-3 -57 -89 0
3 58 90 0
-3 59 91 0
3 60 -92 0
3 61 93 0
-3 -62 94 0
-3 -63 -95 0
3 64 96 0
-3 65 97 0
3 66 -98 0
4 5 34 0
-4 35 -67 0
4 36 68 0
4 37 69 0
-4 -38 70 0
-4 -39 -71 0
4 40 72 0
-4 41 73 0
4 42 -74 0
4 43 75 0
-4 -44 76 0
-4 -45 -77 0
4 46 78 0
-4 47 79 0
4 48 -80 0
4 49 81 0
-4 -50 82 0
-4 -51 -83 0
4 52 84 0
-4 53 85 0
4 54 -86 0
4 55 87 0
-4 -56 88 0
-4 -57 -89 0
4 58 90 0
-4 59 91 0
4 60 -92 0
4 61 93 0
-4 -62 94 0
-4 -63 -95 0
4 64 96 0
-4 65 97 0
4 66 -98 0
-5 6 34 0
-5 35 -67 0
-5 36 68 0
-5 37 69 0
5 -38 70 0
5 -39 -71 0
-5 40 72 0
5 41 73 0
-5 42 -74 0
-5 43 75 0
5 -44 76 0
5 -45 -77 0
-5 46 78 0
5 47 79 0
-5 48 -80 0
-5 49 81 0
5 -50 82 0
5 -51 -83 0
-5 52 84 0
5 53 85 0
-5 54 -86 0
-5 55 87 0
5 -56 88 0
5 -57 -89 0
-5 58 90 0
5 59 91 0
-5 60 -92 0
-5 61 93 0
5 -62 94 0
5 -63 -95 0
-5 64 96 0
5 65 97 0
-5 66 -98 0
-6 7 34 0
-6 35 -67 0
-6 36 68 0
-6 37 69 0
6 -38 70 0
6 -39 -71 0
-6 40 72 0
6 41 73 0
-6 42 -74 0
-6 43 75 0
6 -44 76 0
6 -45 -77 0
-6 46 78 0
6 47 79 0
-6 48 -80 0
-6 49 81 0
6 -50 82 0
6 -51 -83 0
-6 52 84 0
6 53 85 0
-6 54 -86 0
-6 55 87 0
6 -56 88 0
6 -57 -89 0
-6 58 90 0
6 59 91 0
-6 60 -92 0
-6 61 93 0
6 -62 94 0
6 -63 -95 0
-6 64 96 0
6 65 97 0
-6 66 -98 0
7 8 99 0
7 8 -99 0
-7 -8 100 0
7 -8 -100 0
-9 10 99 0
-9 10 -99 0
9 -10 100 0
-9 -10 -100 0
-11 12 99 0
-11 12 -99 0
11 -12 100 0
-11 -12 -100 0
-13 14 99 0
-13 14 -99 0
13 -14 100 0
-13 -14 -100 0
-15 16 99 0
-15 16 -99 0
15 -16 100 0
-15 -16 -100 0
-17 18 99 0
-17 18 -99 0
17 -18 100 0
-17 -18 -100 0
-19 20 99 0
-19 20 -99 0
19 -20 100 0
-19 -20 -100 0
-21 22 99 0
-21 22 -99 0
21 -22 100 0
-21 -22 -100 0
-23 24 99 0
-23 24 -99 0
23 -24 100 0
-23 -24 -100 0
-25 26 99 0
-25 26 -99 0
25 -26 100 0
-25 -26 -100 0
-27 28 99 0
-27 28 -99 0
27 -28 100 0
-27 -28 -100 0
-29 30 99 0
-29 30 -99 0
29 -30 100 0
-29 -30 -100 0
-31 32 99 0
-31 32 -99 0
31 -32 100 0
-31 -32 -100 0
-33 -34 99 0
-33 -34 -99 0
33 34 100 0
-33 34 -100 0
"""

SATLIB_TEST_SUITE = {
    "uf20-01": UF20_01_CNF,
    "aim-50-yes": AIM50_YES_CNF,
    "uf100-01": UF100_01_CNF, # <-- NEW HARD BENCHMARK
}

# -----------------------
# Helper Functions
# -----------------------

def parse_dimacs_cnf(file_content: str) -> Tuple[List[Tuple[int, ...]], int]:
    """
    Parses a DIMACS CNF file string into a list of clauses and n_vars.
    """
    clauses = []
    n_vars = 0
    
    current_clause = []
    for line in file_content.splitlines():
        line = line.strip()
        if not line or line.startswith('c'):
            continue
        
        if line.startswith('p cnf'):
            parts = line.split()
            n_vars = int(parts[2])
            continue
        
        try:
            # Fix for malformed lines like '1. -23 -48 0'
            line = line.replace('.', ' ')
            literals = [int(lit) for lit in line.split()]
            for lit in literals:
                if lit == 0:
                    if current_clause:
                        clauses.append(tuple(current_clause))
                    current_clause = []
                else:
                    current_clause.append(lit)
        except ValueError:
            print(f"Warning: Skipping malformed line: {line}")
            
    if current_clause:
        clauses.append(tuple(current_clause))
        
    return clauses, n_vars

def paramindex_to_subset_v2(parameter_index: int, n_vars: int, n_mask_bits: int) -> List[int]:
    """
    V2 mapping: Maps a param index to a 0-indexed variable subset.
    """
    if n_vars <= 0: return []
    mask_value = parameter_index & ((1 << n_mask_bits) - 1)
    subset = set()
    for i in range(n_mask_bits):
        if (mask_value >> i) & 1:
            var_index_0_based = (i % n_vars)
            subset.add(var_index_0_based)
    return list(subset)

def verify_solution(clauses: List[Tuple[int, ...]], assignment: Dict[int, bool]) -> bool:
    """
    Verifies that a 0-indexed assignment satisfies a list of 1-indexed clauses.
    """
    if assignment is None: return False
    for clause in clauses:
        satisfied = False
        for lit in clause:
            var_0_idx = abs(lit) - 1
            is_positive = (lit > 0)
            if var_0_idx in assignment and assignment[var_0_idx] == is_positive:
                satisfied = True
                break
        if not satisfied:
            return False
    return True

def reduce_problem_by_fixing(sat_problem: qls.SATProblem, fixed_assign: Dict[int,bool]):
    """
    Reduces a SATProblem given a 0-indexed fixed assignment.
    Returns: (reduced_problem, remaining_vars_global_0_indexed)
    """
    all_original_vars_0_idx = set(range(sat_problem.n_vars))
    remaining_vars_global_0_idx = sorted(list(all_original_vars_0_idx - set(fixed_assign.keys())))
    global_to_local_map = {global_var_0_idx: i + 1 for i, global_var_0_idx in enumerate(remaining_vars_global_0_idx)}
    
    new_clauses = []
    
    for clause_obj in sat_problem.clauses:
        clause = clause_obj.literals
        satisfied = False
        new_clause_literals = []
        
        for lit in clause:
            var_0_idx = abs(lit) - 1
            is_positive = (lit > 0)
            
            if var_0_idx in fixed_assign:
                if fixed_assign[var_0_idx] == is_positive:
                    satisfied = True
                    break
                else:
                    continue
            
            if var_0_idx in global_to_local_map:
                new_local_var_1_idx = global_to_local_map[var_0_idx]
                new_lit = new_local_var_1_idx if is_positive else -new_local_var_1_idx
                new_clause_literals.append(new_lit)
        
        if satisfied:
            continue
            
        if not new_clause_literals:
            return None, None # Contradiction
            
        new_clauses.append(qls.SATClause(tuple(new_clause_literals)))
        
    reduced_n_vars = len(remaining_vars_global_0_idx)
    reduced_problem = qls.SATProblem(n_vars=reduced_n_vars, clauses=new_clauses)
    
    return reduced_problem, remaining_vars_global_0_idx

def try_candidate_backdoor_pysat(
    sat_problem: qls.SATProblem, 
    candidate_subset_0_idx: List[int]
) -> Optional[Dict[int, bool]]:
    """
    True FPT step: O(2^k' * poly(N)).
    Tests all 2^k' assignments for the candidate subset.
    Returns a full 0-indexed solution if one is found.
    """
    if not PYSAT_AVAILABLE:
        print("Error: `try_candidate_backdoor_pysat` called but PySAT is not available.")
        return None

    k_prime = len(candidate_subset_0_idx)
    
    # Handle k_prime = 0 case (empty subset)
    if k_prime == 0:
        fixed_assign_0_idx = {}
        reduced, remaining_vars_global_0_idx = reduce_problem_by_fixing(sat_problem, fixed_assign_0_idx)
        
        if reduced is None:
            return None # Contradiction
        
        solver = Glucose3()
        for clause_obj in reduced.clauses:
            solver.add_clause(list(clause_obj.literals))
        
        if solver.solve() == True:
            model = solver.get_model()
            solver.delete()
            
            full_assign_0_idx = {}
            for local_lit_1_idx in model:
                local_var_0_idx = abs(local_lit_1_idx) - 1
                val = (local_lit_1_idx > 0)
                if local_var_0_idx < len(remaining_vars_global_0_idx):
                    global_var_0_idx = remaining_vars_global_0_idx[local_var_0_idx]
                    full_assign_0_idx[global_var_0_idx] = val
            
            # Add any remaining vars not in model
            for var_0_idx in remaining_vars_global_0_idx:
                 if var_0_idx not in full_assign_0_idx:
                    full_assign_0_idx[var_0_idx] = True
            return full_assign_0_idx
        else:
            solver.delete()
            return None
    
    # Normal case: k_prime > 0
    for bits in product([False, True], repeat=k_prime):
        fixed_assign_0_idx = {var_0_idx: val for var_0_idx, val in zip(candidate_subset_0_idx, bits)}
        
        reduced, remaining_vars_global_0_idx = reduce_problem_by_fixing(sat_problem, fixed_assign_0_idx)
        
        if reduced is None:
            continue # Contradiction
            
        if not reduced.clauses:
            # All clauses satisfied by fixed_assign alone!
            full_assign_0_idx = fixed_assign_0_idx.copy()
            for var_0_idx in remaining_vars_global_0_idx:
                full_assign_0_idx[var_0_idx] = True # Assign arbitrarily
            return full_assign_0_idx

        # Solve the reduced problem with PySAT (polynomial time)
        solver = Glucose3()
        for clause_obj in reduced.clauses:
            solver.add_clause(list(clause_obj.literals))
            
        if solver.solve() == True:
            model = solver.get_model() # 1-indexed local literals
            solver.delete()
            
            sol_reduced_0_idx = {} # {global_0_idx: val}
            for local_lit_1_idx in model:
                local_var_1_idx = abs(local_lit_1_idx)
                local_var_0_idx = local_var_1_idx - 1
                val = (local_lit_1_idx > 0)
                
                if local_var_0_idx < len(remaining_vars_global_0_idx):
                    global_var_0_idx = remaining_vars_global_0_idx[local_var_0_idx]
                    sol_reduced_0_idx[global_var_0_idx] = val
                
            full_assign_0_idx = fixed_assign_0_idx.copy()
            full_assign_0_idx.update(sol_reduced_0_idx)
            
            for var_0_idx in remaining_vars_global_0_idx:
                if var_0_idx not in full_assign_0_idx:
                    full_assign_0_idx[var_0_idx] = True # Assign arbitrarily
            
            return full_assign_0_idx
        else:
            solver.delete()
            continue
            
    return None

def extract_subset_from_top_samples(
    samples_norm: Dict[int, float], 
    n_vars: int, 
    topT: int, 
    threshold: float, 
    n_mask_bits: int
) -> List[int]:
    """
    Implements frequency-based extraction.
    Finds a single candidate "superset" backdoor from the top T samples.
    """
    top_samples = sorted(samples_norm.items(), key=lambda kv: kv[1], reverse=True)[:topT]
    
    var_scores = [0.0] * n_vars
    for idx, prob in top_samples:
        subset = paramindex_to_subset_v2(idx, n_vars, n_mask_bits)
        for v in subset: # v is 0-indexed
            if 0 <= v < n_vars:
                var_scores[v] += prob
            
    # Pick variables with a score >= threshold
    chosen = [i for i, score in enumerate(var_scores) if score >= threshold]
    
    # If none meet the threshold, take the top-k highest scoring
    if not chosen:
        k = min(6, n_vars) # Fallback: take top 6
        chosen = sorted(range(n_vars), key=lambda i: var_scores[i], reverse=True)[:k]
        
    return chosen

def shrink_superset_greedy(
    sat_problem: qls.SATProblem, 
    S_0_idx: List[int]
) -> List[int]:
    """
    Implements backward-elimination shrink.
    Takes a candidate superset `S_0_idx` and greedily removes variables
    while checking if the problem remains solvable.
    """
    S = set(S_0_idx)
    # Iterate over a *copy* of the set while modifying the original
    for v in list(S):
        cand_subset = list(S - {v})
        # Note: cand_subset can become empty here, which is fine.
        
        # Check if the problem is *still* solvable with this smaller subset
        sol = try_candidate_backdoor_pysat(sat_problem, cand_subset)
        if sol is not None:
            # It is! The variable v was not necessary.
            # Permanently remove it from our set S.
            S.remove(v)
            
    return sorted(list(S))

def is_minimal_backdoor(sat_problem: qls.SATProblem, S_0_idx: List[int]) -> bool:
    """
    Checks if a *proven* backdoor S is minimal.
    """
    if not S_0_idx: # An empty backdoor is minimal
        return True
        
    for v in S_0_idx:
        cand_subset = [x for x in S_0_idx if x != v]
        # Check if this subset *also* solves the problem
        sol = try_candidate_backdoor_pysat(sat_problem, cand_subset)
        if sol is not None:
            # We found a solution *without* v, so S was not minimal.
            return False
            
    # We tried removing every variable one by one, and all attempts
    # failed to find a solution. Therefore, S is minimal.
    return True

# --- NEW: CLASSICAL BASELINE FUNCTION ---
def solve_classical_baseline(
    clauses: List[Tuple[int, ...]],
    n_vars: int,
    timeout_s: float
) -> Tuple[float, Optional[bool]]:
    """
    Solves the problem directly with PySAT to get a baseline time.
    
    Returns:
        (solve_time, is_sat)
        is_sat is None if timeout occurs.
    """
    if not PYSAT_AVAILABLE:
        return -1.0, None
        
    try:
        # PySAT's Glucose3 solver has a 'budget' parameter
        # which is a rough proxy for time. A better way is
        # to use signals, but that's complex. We'll use
        # a simpler timer and interrupt.
        # For this test, we'll just time it.
        
        solver = Glucose3()
        for c in clauses:
            solver.add_clause(list(c))
            
        t_start = time.time()
        # Note: PySAT's solve_limited is not a time limit,
        # but a limit on 'conflicts' or 'propagations'.
        # We'll just run solve() and time it.
        is_sat = solver.solve()
        t_end = time.time()
        
        solve_time = t_end - t_start
        solver.delete()
        
        if solve_time > timeout_s:
            return solve_time, None # Timed out
            
        return solve_time, bool(is_sat)
        
    except Exception as e:
        print(f"  Error in classical baseline: {e}")
        return -1.0, None

# -----------------------
# Single trial runner
# -----------------------
def run_trial(
    clauses: List[Tuple[int, ...]], 
    n_vars: int, 
    problem_name: str, 
    cfg, 
    trial_seed
) -> dict:
    
    # --- NEW: Run Classical Baseline First ---
    print(f"  Running classical baseline (timeout={cfg['classical_timeout_s']}s)...")
    baseline_time, baseline_sat = solve_classical_baseline(
        clauses, n_vars, cfg['classical_timeout_s']
    )
    if baseline_sat is None:
        print(f"  Classical baseline TIMED OUT (>{cfg['classical_timeout_s']}s).")
    else:
        print(f"  Classical baseline: {baseline_time:.4f}s, SAT: {baseline_sat}")
    # ---
    
    try:
        sat_clauses = [qls.SATClause(c) for c in clauses]
        problem = qls.SATProblem(n_vars=n_vars, clauses=sat_clauses)
    except Exception as e:
        return {"status":"error", "error": f"Failed to create SATProblem: {e}", "classical_baseline_time_s": baseline_time}

    start_time_total = time.time()
    
    p_layers = cfg["p_layers"]
    bits_per_param = cfg["bits_per_param"]
    try:
        ansatz, n_params = qls.create_qaoa_ansatz(problem, p_layers)
        vqe_hamiltonian = qls.sat_to_hamiltonian(problem)
    except Exception as e:
        return {"status":"error", "error": f"ansatz/hamiltonian build failed: {e}", "classical_baseline_time_s": baseline_time}

    param_bounds = qls.np.array([[0.0, 2 * qls.np.pi] if i % 2 == 0 else [0.0, qls.np.pi] for i in range(n_params)])
    
    qls.np.random.seed(trial_seed)
    theta0 = qls.np.random.rand(n_params) * (param_bounds[:, 1] - param_bounds[:, 0]) + param_bounds[:, 0]
    
    param_idx, n_qubits_p = qls.encode_parameters(theta0, param_bounds, bits_per_param)
    
    n_mask_bits = cfg["N_MASK_BITS"]
    if n_qubits_p < n_mask_bits:
        return {"status":"error", "error": f"n_qubits_p ({n_qubits_p}) is smaller than N_MASK_BITS ({n_mask_bits})", "classical_baseline_time_s": baseline_time}

    delta_t = 0.35
    try:
        U_PE = qls.build_coherent_phase_oracle_nisq(n_params, bits_per_param, param_bounds, delta_t,
                                                    ansatz, vqe_hamiltonian, problem.n_vars)
        if U_PE is None: raise ValueError("U_PE build returned None")
    except Exception as e:
        return {"status":"error", "error": f"U_PE build failed: {e}", "classical_baseline_time_s": baseline_time}

    T_gate = qls.build_tunneling_operator_QW(n_qubits_p)
    evol_qc = qls.run_qlto_evolution_nisq(n_qubits_p, problem.n_vars, param_idx, U_PE, T_gate, K_steps=3)
    if evol_qc is None:
        return {"status":"error", "error": "evolution circuit build failed", "classical_baseline_time_s": baseline_time}

    sampler = qls.CountingWrapper(qls.BaseSampler())
    shots = cfg["shots"]

    # --- Quantum Part ---
    t0_sampler = time.time()
    samples = qls.measure_and_process_samples_nisq(evol_qc, shots, n_qubits_p, 'param', sampler)
    t1_sampler = time.time()
    sampler_time = t1_sampler - t0_sampler

    if not samples:
        return {"status":"ok", "success": False, "reason":"no-samples", "sampler_time":sampler_time, "classical_baseline_time_s": baseline_time}
    totalp = sum(samples.values())
    if totalp <= 0:
        return {"status":"ok", "success": False, "reason":"empty-dist", "sampler_time":sampler_time, "classical_baseline_time_s": baseline_time}
    
    samples_norm = {idx: p/totalp for idx,p in samples.items()}
    top_states = sorted(samples_norm.items(), key=lambda kv: kv[1], reverse=True)[:10]
    top_index, top_prob = top_states[0] if top_states else (-1, 0.0)

    # --- Classical Part (New Heuristic) ---
    t_classical_start = time.time()
    
    # 1. Frequency-based extraction
    superset = extract_subset_from_top_samples(
        samples_norm, problem.n_vars, 
        topT=cfg["top_T_candidates"], 
        threshold=cfg["freq_threshold"], 
        n_mask_bits=n_mask_bits
    )
    k_prime_initial = len(superset)
    
    # 2. Backward-elimination shrink
    shrunk_set = shrink_superset_greedy(problem, superset)
    k_prime_final = len(shrunk_set)
    
    # 3. Final attempt with the shrunk set
    solution_0_idx = try_candidate_backdoor_pysat(problem, shrunk_set)
    
    is_minimal = None
    if solution_0_idx is not None:
        is_minimal = is_minimal_backdoor(problem, shrunk_set)
    
    t_classical_end = time.time()
    classical_search_time = t_classical_end - t_classical_start
    total_time = time.time() - start_time_total # Pipeline time

    if solution_0_idx is not None:
        sat_ok = verify_solution([c.literals for c in problem.clauses], solution_0_idx)
        
        # Cross-check with baseline
        if baseline_sat is not None and baseline_sat != sat_ok:
             print(f"  *** CRITICAL WARNING: Pipeline result ({sat_ok}) disagrees with baseline ({baseline_sat}) ***")

        return {
            "status": "ok",
            "success": sat_ok,
            "classical_baseline_time_s": baseline_time, # <-- NEW
            "classical_baseline_sat": baseline_sat,     # <-- NEW
            "k_prime_initial": k_prime_initial,
            "k_prime_final": k_prime_final,
            "is_minimal": is_minimal,
            "subset": shrunk_set,
            "top_index": top_index,
            "top_prob": top_prob,
            "sampler_time": sampler_time,
            "classical_search_time": classical_search_time,
            "total_time": total_time,
        }
    else:
        # No solution found
        
        # Cross-check with baseline
        if baseline_sat is not None and baseline_sat != False:
             print(f"  *** CRITICAL WARNING: Pipeline result (UNSAT) disagrees with baseline (SAT) ***")

        return {
            "status": "ok",
            "success": False, # No solution found
            "reason": "no-solution-from-heuristic",
            "classical_baseline_time_s": baseline_time, # <-- NEW
            "classical_baseline_sat": baseline_sat,     # <-- NEW
            "k_prime_initial": k_prime_initial,
            "k_prime_final": k_prime_final,
            "is_minimal": None,
            "top_index": top_index,
            "top_prob": top_prob,
            "sampler_time": sampler_time,
            "classical_search_time": classical_search_time,
            "total_time": total_time,
        }

# -----------------------
# Main sweep & CSV logging
# -----------------------
def run_sweep(cfg):
    out_csv = cfg["output_csv"]
    header = [
        "problem_name", "N", "M", "trial", "status", "success", 
        "classical_baseline_time_s", "classical_baseline_sat", # <-- NEW
        "k_prime_initial", "k_prime_final", "is_minimal",
        "top_index", "top_prob",
        "sampler_time", "classical_search_time", "total_time", "reason"
    ]
    
    with open(out_csv, "w", newline="") as f:
        writer = csv.DictWriter(f, fieldnames=header)
        writer.writeheader()

    trial_global_seed = cfg["random_seed"]
    
    total_runs = len(SATLIB_TEST_SUITE) * cfg["trials_per_setting"]
    run_count = 0
    
    print("="*80)
    print("Running True FPT Solver v7 (Hard Benchmark Test)")
    print(f"Test Suite: {list(SATLIB_TEST_SUITE.keys())}")
    print(f"Trials per problem: {cfg['trials_per_setting']}")
    print(f"PySAT Enabled: {PYSAT_AVAILABLE}")
    print("="*80)
    
    if not PYSAT_AVAILABLE:
        print("CRITICAL ERROR: PySAT not found. Aborting sweep.")
        return

    for problem_name, cnf_content in SATLIB_TEST_SUITE.items():
        
        try:
            clauses, n_vars = parse_dimacs_cnf(cnf_content)
            n_clauses = len(clauses)
        except Exception as e:
            print(f"\nFailed to parse problem {problem_name}: {e}")
            continue
            
        for t in range(cfg["trials_per_setting"]):
            run_count += 1
            trial_seed = trial_global_seed + run_count
            print(f"\n[Run {run_count}/{total_runs}] Problem={problem_name} N={n_vars} M={n_clauses} trial={t+1}")
            
            res = run_trial(clauses, n_vars, problem_name, cfg, trial_seed)
            
            row = {
                "problem_name": problem_name,
                "N": n_vars,
                "M": n_clauses,
                "trial": t+1,
                "status": res.get("status"),
                "success": res.get("success", False),
                "classical_baseline_time_s": res.get("classical_baseline_time_s", ""), # <-- NEW
                "classical_baseline_sat": res.get("classical_baseline_sat", ""),     # <-- NEW
                "k_prime_initial": res.get("k_prime_initial", ""),
                "k_prime_final": res.get("k_prime_final", ""),
                "is_minimal": res.get("is_minimal", ""),
                "top_index": res.get("top_index", ""),
                "top_prob": res.get("top_prob", ""),
                "sampler_time": res.get("sampler_time", ""),
                "classical_search_time": res.get("classical_search_time", ""),
                "total_time": res.get("total_time", ""),
                "reason": res.get("reason", "")
            }
            
            with open(out_csv, "a", newline="") as f:
                writer = csv.DictWriter(f, fieldnames=header)
                writer.writerow(row)
                
            print("-> result:", {k:v for k,v in row.items() if k not in ["problem_name", "N", "M"]})

    print(f"\nSweep finished. Results saved to {out_csv}")
    
    # --- Final Analysis ---
    print("\n" + "="*80)
    print("Final Experiment Analysis (v7)")
    print("="*80)
    try:
        import pandas as pd
        df = pd.read_csv(out_csv)
        
        for name in df['problem_name'].unique():
            print(f"\nResults for: {name}")
            df_problem = df[df['problem_name'] == name]
            success_rate = df_problem['success'].mean()
            print(f"  Success Rate: {success_rate*100:.1f}% ({df_problem['success'].sum()}/{len(df_problem)})")
            
            # Get baseline results (should be the same for all trials)
            baseline_time = df_problem['classical_baseline_time_s'].mean()
            baseline_sat = df_problem['classical_baseline_sat'].iloc[0]
            if baseline_time > cfg['classical_timeout_s']:
                print(f"  Classical Baseline: TIMEOUT (>{cfg['classical_timeout_s']}s)")
            else:
                print(f"  Classical Baseline: {baseline_time:.4f}s (Result: {baseline_sat})")

            if success_rate > 0:
                df_success = df_problem[df_problem['success'] == True]
                print(f"  Avg k' (initial): {df_success['k_prime_initial'].mean():.2f}")
                print(f"  Avg k' (final, shrunk): {df_success['k_prime_final'].mean():.2f}")
                minimal_rate = df_success['is_minimal'].mean()
                print(f"  Minimality Rate: {minimal_rate*100:.1f}%")
                
                avg_pipeline_time = df_success['total_time'].mean()
                print(f"  Avg Pipeline Time: {avg_pipeline_time:.3f}s")
                print(f"    (Quantum Sampler: {df_success['sampler_time'].mean():.3f}s, Classical Search: {df_success['classical_search_time'].mean():.3f}s)")
                
                # --- The Key Metric ---
                if baseline_time > avg_pipeline_time:
                    speedup = baseline_time / avg_pipeline_time
                    print(f"  üöÄ QUANTUM SPEEDUP: {speedup:.2f}x")
                else:
                    print(f"  (No speedup vs classical baseline)")
                    
            else:
                if not baseline_sat:
                    print(f"  Success Rate is 0%, which is CORRECT for this UNSAT problem.")
                else:
                    print(f"  Avg Total Time (failures): {df_problem['total_time'].mean():.3f}s")
                    
    except ImportError:
        print("Install 'pandas' for a final summary: pip install pandas")
    except FileNotFoundError:
        print(f"Could not read {out_csv} for summary.")


if __name__ == "__main__":
    if not qls.QISKIT_AVAILABLE:
        print("Error: Qiskit not found. Please install qiskit and qiskit-aer.")
    elif not PYSAT_AVAILABLE:
        print("Error: PySAT not found. Please install python-sat.")
    else:
        run_sweep(CONFIG)
