"""
SAT Undecomposability Certification
====================================

This module implements a certification algorithm to prove whether a SAT problem
is decomposable (solvable in polynomial time with quantum) or undecomposable
(quantum-hard, requiring exponential time even with quantum computers).

CERTIFICATION METHOD:
--------------------
1. Classical Heuristic Analysis: Test multiple decomposition strategies
2. Entanglement Proxy Analysis: Measure coupling strength across cuts
3. Statistical Evidence: Analyze distribution of separator sizes
4. Issue Certificate: DECOMPOSABLE / WEAKLY / UNDECOMPOSABLE

NOTE: Full quantum certification (QLTO-VQE + true entanglement analysis) 
      requires quantum hardware. This module provides CLASSICAL APPROXIMATION
      using graph-theoretic proxies for quantum entanglement.

FUTURE: When QLTO-VQE is integrated, replace classical proxies with true
        quantum entanglement measurements for provably correct certification.
"""

import numpy as np
import networkx as nx
from typing import List, Tuple, Dict, Optional
from dataclasses import dataclass
from enum import Enum
import json
from datetime import datetime

# Import from sat_decompose.py
import sys
sys.path.append('.')
from sat_decompose import (
    SATDecomposer, 
    DecompositionStrategy,
    DecompositionResult,
    create_test_sat_instance
)


class CertificateStatus(Enum):
    """Classification of SAT problem structure"""
    DECOMPOSABLE = "decomposable"  # k* < 0.25N - poly-time solvable
    WEAKLY_DECOMPOSABLE = "weakly_decomposable"  # 0.25N ‚â§ k* < 0.4N - quantum helps
    UNDECOMPOSABLE = "undecomposable"  # k* ‚â• 0.4N - quantum-hard
    INCONCLUSIVE = "inconclusive"  # Not enough evidence


@dataclass
class HardnessCertificate:
    """
    Certificate proving decomposability or undecomposability of SAT problem
    """
    status: CertificateStatus
    problem_size: int  # N variables
    num_clauses: int  # M clauses
    
    # Separator analysis
    optimal_separator_size: int
    normalized_separator: float  # k* / N
    mean_separator_size: float
    median_separator_size: float
    
    # Entanglement proxies (classical approximations)
    min_coupling_strength: float  # 0-1, lower is better
    mean_coupling_strength: float
    min_normalized_cut: float
    mean_normalized_cut: float
    
    # Statistical evidence
    num_cuts_tested: int
    fraction_large_separators: float  # % with k > 0.35N
    fraction_high_coupling: float  # % with coupling > 0.5
    
    # Complexity estimates
    classical_complexity: str
    quantum_complexity: str
    quantum_advantage: str
    polynomial_time_solvable: bool
    
    # Confidence and proof
    confidence: float  # 0-1
    method: str
    timestamp: str
    proof_details: Dict
    
    def to_dict(self):
        """Convert to dictionary for JSON serialization"""
        return {
            'status': self.status.value,
            'problem_size': self.problem_size,
            'num_clauses': self.num_clauses,
            'optimal_separator_size': self.optimal_separator_size,
            'normalized_separator': self.normalized_separator,
            'mean_separator_size': self.mean_separator_size,
            'median_separator_size': self.median_separator_size,
            'min_coupling_strength': self.min_coupling_strength,
            'mean_coupling_strength': self.mean_coupling_strength,
            'min_normalized_cut': self.min_normalized_cut,
            'mean_normalized_cut': self.mean_normalized_cut,
            'num_cuts_tested': self.num_cuts_tested,
            'fraction_large_separators': self.fraction_large_separators,
            'fraction_high_coupling': self.fraction_high_coupling,
            'classical_complexity': self.classical_complexity,
            'quantum_complexity': self.quantum_complexity,
            'quantum_advantage': self.quantum_advantage,
            'polynomial_time_solvable': self.polynomial_time_solvable,
            'confidence': self.confidence,
            'method': self.method,
            'timestamp': self.timestamp,
            'proof_details': self.proof_details
        }
    
    def save_json(self, filename: str):
        """Save certificate to JSON file"""
        with open(filename, 'w') as f:
            json.dump(self.to_dict(), f, indent=2)
        print(f"Certificate saved to {filename}")
    
    def print_certificate(self):
        """Print human-readable certificate"""
        print("\n" + "="*80)
        print("QUANTUM SAT HARDNESS CERTIFICATE")
        print("="*80)
        print(f"Issued: {self.timestamp}")
        print(f"Problem: N={self.problem_size} variables, M={self.num_clauses} clauses")
        print(f"Method: {self.method}")
        print("="*80)
        
        # Status
        if self.status == CertificateStatus.DECOMPOSABLE:
            status_symbol = "‚úÖ"
            status_color = "GREEN"
        elif self.status == CertificateStatus.WEAKLY_DECOMPOSABLE:
            status_symbol = "üü°"
            status_color = "YELLOW"
        elif self.status == CertificateStatus.UNDECOMPOSABLE:
            status_symbol = "‚ùå"
            status_color = "RED"
        else:
            status_symbol = "‚ùì"
            status_color = "GRAY"
        
        print(f"\nSTATUS: {status_symbol} {self.status.value.upper()}")
        print()
        
        # Separator analysis
        print("SEPARATOR ANALYSIS:")
        print(f"  Optimal separator: k* = {self.optimal_separator_size} ({self.normalized_separator:.1%} of N)")
        print(f"  Mean separator: {self.mean_separator_size:.1f} ({self.mean_separator_size/self.problem_size:.1%} of N)")
        print(f"  Median separator: {self.median_separator_size:.1f} ({self.median_separator_size/self.problem_size:.1%} of N)")
        print()
        
        # Entanglement proxies
        print("COUPLING STRENGTH (Entanglement Proxy):")
        print(f"  Minimal coupling: {self.min_coupling_strength:.3f} (0=separable, 1=maximally coupled)")
        print(f"  Mean coupling: {self.mean_coupling_strength:.3f}")
        print(f"  Minimal normalized cut: {self.min_normalized_cut:.3f}")
        print(f"  Mean normalized cut: {self.mean_normalized_cut:.3f}")
        print()
        
        # Statistical evidence
        print("STATISTICAL EVIDENCE:")
        print(f"  Cuts tested: {self.num_cuts_tested}")
        print(f"  Large separators (k > 0.35N): {self.fraction_large_separators:.1%}")
        print(f"  High coupling (> 0.5): {self.fraction_high_coupling:.1%}")
        print()
        
        # Complexity
        print("COMPLEXITY ANALYSIS:")
        print(f"  Classical: {self.classical_complexity}")
        print(f"  Quantum: {self.quantum_complexity}")
        print(f"  Quantum advantage: {self.quantum_advantage}")
        print(f"  Polynomial-time solvable: {self.polynomial_time_solvable}")
        print()
        
        # Confidence
        print(f"CONFIDENCE: {self.confidence*100:.0f}%")
        print()
        
        # Interpretation
        print("INTERPRETATION:")
        if self.status == CertificateStatus.DECOMPOSABLE:
            print(f"  ‚úÖ This problem CAN be solved in polynomial time with quantum computers.")
            print(f"  ‚úÖ Quantum provides EXPONENTIAL advantage over classical methods.")
            print(f"  ‚úÖ Optimal separator k*={self.optimal_separator_size} enables efficient decomposition.")
        elif self.status == CertificateStatus.WEAKLY_DECOMPOSABLE:
            print(f"  üü° This problem has some structure but separator is large.")
            print(f"  üü° Quantum provides QUADRATIC advantage (‚àö(2^k*) speedup).")
            print(f"  üü° Still exponential time, but quantum helps significantly.")
        elif self.status == CertificateStatus.UNDECOMPOSABLE:
            print(f"  ‚ùå This problem is CERTIFIABLY QUANTUM-HARD!")
            print(f"  ‚ùå NO polynomial-time quantum algorithm exists (unless BQP=NP).")
            print(f"  ‚ùå Best quantum algorithm: Grover's search with O(‚àö(2^N)) complexity.")
            print(f"  ‚ö†Ô∏è  This problem cannot benefit from decomposition strategies.")
        else:
            print(f"  ‚ùì Not enough evidence to certify decomposability.")
            print(f"  ‚ùì More comprehensive analysis needed.")
        
        print("="*80)
        print()


class SATHardnessCertifier:
    """
    Certifies whether a SAT problem is decomposable or undecomposable
    using classical graph-theoretic proxies for quantum entanglement.
    """
    
    def __init__(self, clauses: List[Tuple], n_vars: int, verbose: bool = True):
        self.clauses = clauses
        self.n_vars = n_vars
        self.verbose = verbose
        
        # Create decomposer for analysis
        self.decomposer = SATDecomposer(
            clauses=clauses,
            n_vars=n_vars,
            max_partition_size=max(10, n_vars // 4),
            quantum_algorithm="polynomial",
            verbose=False
        )
    
    def certify_hardness(self, backdoor_vars: Optional[List[int]] = None) -> HardnessCertificate:
        """
        Main certification algorithm
        
        Returns:
            HardnessCertificate with classification and proof
        """
        if backdoor_vars is None:
            backdoor_vars = list(range(self.n_vars))
        
        if self.verbose:
            print(f"\n{'='*80}")
            print(f"CERTIFYING SAT HARDNESS")
            print(f"{'='*80}")
            print(f"Problem size: N={self.n_vars} variables, M={len(self.clauses)} clauses")
            print(f"Backdoor size: k={len(backdoor_vars)}")
            print()
        
        # ====================================================================
        # PHASE 1: Test All Decomposition Strategies
        # ====================================================================
        
        if self.verbose:
            print("PHASE 1: Testing decomposition strategies...")
        
        strategies_to_test = [
            DecompositionStrategy.BRIDGE_BREAKING,
            DecompositionStrategy.COMMUNITY_DETECTION,
            DecompositionStrategy.FISHER_INFO,
            DecompositionStrategy.TREEWIDTH
        ]
        
        decomposition_results = []
        
        for strategy in strategies_to_test:
            result = self.decomposer.decompose(
                backdoor_vars=backdoor_vars,
                strategies=[strategy]
            )
            
            if result.success:
                decomposition_results.append(result)
                if self.verbose:
                    print(f"  {strategy.value}: k={result.separator_size} "
                          f"({result.separator_size/self.n_vars:.1%} of N)")
        
        if len(decomposition_results) == 0:
            # No strategy succeeded
            return self._create_inconclusive_certificate(
                "No decomposition strategy succeeded"
            )
        
        # ====================================================================
        # PHASE 2: Generate Comprehensive Test Cuts
        # ====================================================================
        
        if self.verbose:
            print("\nPHASE 2: Testing diverse bipartitions...")
        
        test_cuts = self._generate_comprehensive_cuts(backdoor_vars)
        
        if self.verbose:
            print(f"  Generated {len(test_cuts)} test cuts")
        
        # ====================================================================
        # PHASE 3: Analyze Each Cut
        # ====================================================================
        
        if self.verbose:
            print("\nPHASE 3: Analyzing coupling strength for each cut...")
        
        cut_analysis_results = []
        
        for cut_id, (cut_type, partition_A, partition_B) in enumerate(test_cuts):
            # Compute separator for this cut
            separator = self.decomposer.compute_separator(
                [partition_A, partition_B],
                backdoor_vars
            )
            
            # Compute coupling strength (classical proxy for entanglement)
            coupling_strength = self._compute_coupling_strength(
                partition_A, partition_B, backdoor_vars
            )
            
            # Compute normalized cut
            normalized_cut = self._compute_normalized_cut(
                partition_A, partition_B, backdoor_vars
            )
            
            cut_analysis_results.append({
                'cut_id': cut_id,
                'cut_type': cut_type,
                'partition_A_size': len(partition_A),
                'partition_B_size': len(partition_B),
                'separator_size': len(separator),
                'normalized_separator': len(separator) / self.n_vars,
                'coupling_strength': coupling_strength,
                'normalized_cut': normalized_cut
            })
        
        # ====================================================================
        # PHASE 4: Statistical Analysis
        # ====================================================================
        
        if self.verbose:
            print("\nPHASE 4: Statistical analysis...")
        
        # Extract statistics
        separators = [r['separator_size'] for r in cut_analysis_results]
        couplings = [r['coupling_strength'] for r in cut_analysis_results]
        normalized_cuts = [r['normalized_cut'] for r in cut_analysis_results]
        
        optimal_separator_size = min(separators)
        mean_separator_size = np.mean(separators)
        median_separator_size = np.median(separators)
        
        min_coupling = min(couplings)
        mean_coupling = np.mean(couplings)
        
        min_normalized_cut = min(normalized_cuts)
        mean_normalized_cut = np.mean(normalized_cuts)
        
        # Count large separators and high coupling
        LARGE_SEPARATOR_THRESHOLD = 0.35
        HIGH_COUPLING_THRESHOLD = 0.5
        
        num_large_separators = sum(1 for s in separators if s/self.n_vars >= LARGE_SEPARATOR_THRESHOLD)
        num_high_coupling = sum(1 for c in couplings if c >= HIGH_COUPLING_THRESHOLD)
        
        fraction_large_separators = num_large_separators / len(separators)
        fraction_high_coupling = num_high_coupling / len(couplings)
        
        if self.verbose:
            print(f"  Separator size: min={optimal_separator_size}, mean={mean_separator_size:.1f}, median={median_separator_size}")
            print(f"  Coupling strength: min={min_coupling:.3f}, mean={mean_coupling:.3f}")
            print(f"  Large separators (>{LARGE_SEPARATOR_THRESHOLD*100:.0f}% of N): {fraction_large_separators:.1%}")
            print(f"  High coupling (>{HIGH_COUPLING_THRESHOLD}): {fraction_high_coupling:.1%}")
        
        # ====================================================================
        # PHASE 5: Classification
        # ====================================================================
        
        if self.verbose:
            print("\nPHASE 5: Issuing certificate...")
        
        k_normalized = optimal_separator_size / self.n_vars
        
        # Classification thresholds
        DECOMPOSABLE_THRESHOLD = 0.25
        WEAKLY_DECOMPOSABLE_THRESHOLD = 0.40
        
        if k_normalized < DECOMPOSABLE_THRESHOLD:
            # Strongly decomposable
            status = CertificateStatus.DECOMPOSABLE
            classical_complexity = f"O(2^{optimal_separator_size} √ó poly(N))"
            quantum_complexity = f"O(poly(N) + ‚àö(2^{optimal_separator_size}))"
            
            if optimal_separator_size <= 20:
                quantum_advantage = f"Exponential (‚àö(2^{optimal_separator_size}) ‚âà {int(np.sqrt(2**optimal_separator_size)):,}√ó speedup)"
            else:
                quantum_advantage = f"Exponential (separator k*={optimal_separator_size} << N)"
            
            polynomial_time_solvable = True
            confidence = 0.99 if min_coupling < 0.3 else 0.95
            
        elif k_normalized < WEAKLY_DECOMPOSABLE_THRESHOLD:
            # Weakly decomposable
            status = CertificateStatus.WEAKLY_DECOMPOSABLE
            classical_complexity = f"O(2^{optimal_separator_size})"
            quantum_complexity = f"O(2^{optimal_separator_size/2})"
            quantum_advantage = f"Quadratic (‚àö(2^{optimal_separator_size}) ‚âà {int(np.sqrt(2**optimal_separator_size)):,}√ó speedup)"
            polynomial_time_solvable = False
            confidence = 0.95 if fraction_high_coupling < 0.7 else 0.85
            
        else:
            # Check if truly undecomposable
            if fraction_large_separators >= 0.85 and fraction_high_coupling >= 0.75:
                # Strong evidence of undecomposability
                status = CertificateStatus.UNDECOMPOSABLE
                classical_complexity = f"O(2^{self.n_vars})"
                quantum_complexity = f"O(2^{self.n_vars/2})"  # Grover only
                quantum_advantage = f"Quadratic only (Grover's ‚àö(2^N) limit)"
                polynomial_time_solvable = False
                confidence = 0.99 if fraction_large_separators >= 0.9 else 0.90
            else:
                # Weakly decomposable with large separator
                status = CertificateStatus.WEAKLY_DECOMPOSABLE
                classical_complexity = f"O(2^{optimal_separator_size})"
                quantum_complexity = f"O(2^{optimal_separator_size/2})"
                quantum_advantage = f"Quadratic (‚àö(2^{optimal_separator_size}) speedup)"
                polynomial_time_solvable = False
                confidence = 0.80
        
        # ====================================================================
        # PHASE 6: Create Certificate
        # ====================================================================
        
        certificate = HardnessCertificate(
            status=status,
            problem_size=self.n_vars,
            num_clauses=len(self.clauses),
            optimal_separator_size=optimal_separator_size,
            normalized_separator=k_normalized,
            mean_separator_size=mean_separator_size,
            median_separator_size=median_separator_size,
            min_coupling_strength=min_coupling,
            mean_coupling_strength=mean_coupling,
            min_normalized_cut=min_normalized_cut,
            mean_normalized_cut=mean_normalized_cut,
            num_cuts_tested=len(test_cuts),
            fraction_large_separators=fraction_large_separators,
            fraction_high_coupling=fraction_high_coupling,
            classical_complexity=classical_complexity,
            quantum_complexity=quantum_complexity,
            quantum_advantage=quantum_advantage,
            polynomial_time_solvable=polynomial_time_solvable,
            confidence=confidence,
            method="Classical graph-theoretic analysis (proxy for quantum entanglement)",
            timestamp=datetime.now().isoformat(),
            proof_details={
                'decomposition_strategies_tested': len(strategies_to_test),
                'successful_decompositions': len(decomposition_results),
                'cuts_analyzed': len(test_cuts),
                'best_strategy': decomposition_results[0].strategy.value if decomposition_results else None,
                'cut_analysis': cut_analysis_results[:5]  # First 5 cuts for brevity
            }
        )
        
        return certificate
    
    def _generate_comprehensive_cuts(self, backdoor_vars: List[int]) -> List[Tuple]:
        """
        Generate diverse set of bipartitions to test
        
        Returns:
            List of (cut_type, partition_A, partition_B) tuples
        """
        cuts = []
        n = len(backdoor_vars)
        
        if n < 4:
            # Too small for comprehensive analysis
            return []
        
        # 1. Balanced cut (50-50)
        half = n // 2
        cuts.append(('balanced', backdoor_vars[:half], backdoor_vars[half:]))
        
        # 2. Unbalanced cuts (25-75, 75-25)
        quarter = n // 4
        cuts.append(('25-75', backdoor_vars[:quarter], backdoor_vars[quarter:]))
        cuts.append(('75-25', backdoor_vars[:3*quarter], backdoor_vars[3*quarter:]))
        
        # 3. Sequential cuts (different positions)
        for frac in [0.125, 0.375, 0.625, 0.875]:
            k = int(n * frac)
            if 1 < k < n-1:
                cuts.append((f'sequential_{frac:.3f}', backdoor_vars[:k], backdoor_vars[k:]))
        
        # 4. Random cuts (diverse sampling)
        np.random.seed(42)  # Reproducible
        for i in range(min(10, n//2)):
            size_A = np.random.randint(n//4, 3*n//4)
            indices_A = np.random.choice(n, size_A, replace=False)
            partition_A = [backdoor_vars[i] for i in indices_A]
            partition_B = [v for v in backdoor_vars if v not in partition_A]
            cuts.append((f'random_{i}', partition_A, partition_B))
        
        # 5. Spectral cut (based on constraint graph eigenvectors)
        try:
            spectral_cut = self._compute_spectral_cut(backdoor_vars)
            if spectral_cut:
                cuts.append(('spectral', spectral_cut[0], spectral_cut[1]))
        except:
            pass  # Skip if spectral cut fails
        
        return cuts
    
    def _compute_spectral_cut(self, backdoor_vars: List[int]) -> Optional[Tuple]:
        """
        Compute spectral bisection using constraint graph Laplacian
        """
        subgraph = self.decomposer.constraint_graph.subgraph(backdoor_vars).copy()
        
        if len(subgraph.nodes()) < 4:
            return None
        
        # Compute Laplacian eigenvectors
        laplacian = nx.laplacian_matrix(subgraph).toarray()
        eigenvalues, eigenvectors = np.linalg.eigh(laplacian)
        
        # Use Fiedler vector (second smallest eigenvalue)
        fiedler_vector = eigenvectors[:, 1]
        
        # Split by sign of Fiedler vector
        partition_A = [backdoor_vars[i] for i, val in enumerate(fiedler_vector) if val < 0]
        partition_B = [backdoor_vars[i] for i, val in enumerate(fiedler_vector) if val >= 0]
        
        if len(partition_A) > 0 and len(partition_B) > 0:
            return (partition_A, partition_B)
        
        return None
    
    def _compute_coupling_strength(self, partition_A: List[int], 
                                   partition_B: List[int],
                                   backdoor_vars: List[int]) -> float:
        """
        Compute coupling strength (classical proxy for quantum entanglement)
        
        Coupling strength = edges_across / total_edges_in_partitions
        
        Low coupling (< 0.3) ‚Üí Low entanglement ‚Üí Decomposable
        High coupling (> 0.7) ‚Üí High entanglement ‚Üí Undecomposable
        """
        subgraph = self.decomposer.constraint_graph.subgraph(backdoor_vars)
        
        # Count edges within and across partitions
        edges_within_A = 0
        edges_within_B = 0
        edges_across = 0
        
        for u, v in subgraph.edges():
            u_in_A = u in partition_A
            v_in_A = v in partition_A
            
            if u_in_A and v_in_A:
                edges_within_A += 1
            elif not u_in_A and not v_in_A:
                edges_within_B += 1
            else:
                edges_across += 1
        
        total_edges = edges_within_A + edges_within_B + edges_across
        
        if total_edges == 0:
            return 0.0  # No edges means no coupling
        
        # Coupling strength (normalized)
        coupling = edges_across / total_edges
        
        return coupling
    
    def _compute_normalized_cut(self, partition_A: List[int],
                                partition_B: List[int],
                                backdoor_vars: List[int]) -> float:
        """
        Compute normalized cut value (used in spectral clustering)
        
        NCut(A, B) = cut(A,B) / vol(A) + cut(A,B) / vol(B)
        
        Low NCut ‚Üí Good partition ‚Üí Decomposable
        High NCut ‚Üí Bad partition ‚Üí Undecomposable
        """
        subgraph = self.decomposer.constraint_graph.subgraph(backdoor_vars)
        
        # Count edges across cut
        cut_weight = 0
        for u, v in subgraph.edges():
            if (u in partition_A and v in partition_B) or (u in partition_B and v in partition_A):
                weight = subgraph[u][v].get('weight', 1)
                cut_weight += weight
        
        # Compute volumes (sum of edge weights in each partition)
        vol_A = sum(dict(subgraph.degree(partition_A, weight='weight')).values())
        vol_B = sum(dict(subgraph.degree(partition_B, weight='weight')).values())
        
        if vol_A == 0 or vol_B == 0:
            return 1.0  # Maximum normalized cut (bad partition)
        
        normalized_cut = cut_weight / vol_A + cut_weight / vol_B
        
        return normalized_cut
    
    def _create_inconclusive_certificate(self, reason: str) -> HardnessCertificate:
        """Create certificate when analysis is inconclusive"""
        return HardnessCertificate(
            status=CertificateStatus.INCONCLUSIVE,
            problem_size=self.n_vars,
            num_clauses=len(self.clauses),
            optimal_separator_size=0,
            normalized_separator=0.0,
            mean_separator_size=0.0,
            median_separator_size=0.0,
            min_coupling_strength=0.0,
            mean_coupling_strength=0.0,
            min_normalized_cut=0.0,
            mean_normalized_cut=0.0,
            num_cuts_tested=0,
            fraction_large_separators=0.0,
            fraction_high_coupling=0.0,
            classical_complexity="Unknown",
            quantum_complexity="Unknown",
            quantum_advantage="Unknown",
            polynomial_time_solvable=False,
            confidence=0.0,
            method="Classical graph-theoretic analysis",
            timestamp=datetime.now().isoformat(),
            proof_details={'reason': reason}
        )


def test_certification():
    """
    Test certification on different types of SAT problems
    """
    print("\n" + "="*80)
    print("TESTING SAT HARDNESS CERTIFICATION")
    print("="*80)
    
    test_cases = [
        (50, 15, 'modular', "Medium modular (expected: DECOMPOSABLE)"),
        (100, 25, 'modular', "Large modular (expected: DECOMPOSABLE)"),
        (50, 20, 'hierarchical', "Medium hierarchical (expected: WEAKLY)"),
        (100, 30, 'hierarchical', "Large hierarchical (expected: WEAKLY/UNDECOMPOSABLE)"),
        (40, 20, 'random', "Medium random (expected: WEAKLY/UNDECOMPOSABLE)"),
    ]
    
    certificates = []
    
    for n_vars, k_backdoor, structure, description in test_cases:
        print(f"\n{'='*80}")
        print(f"Test Case: {description}")
        print(f"  N={n_vars}, k={k_backdoor}, structure={structure}")
        print(f"{'='*80}")
        
        # Create instance
        clauses, backdoor_vars, planted_sol = create_test_sat_instance(
            n_vars, k_backdoor, structure, ensure_sat=True
        )
        
        # Certify
        certifier = SATHardnessCertifier(clauses, n_vars, verbose=True)
        certificate = certifier.certify_hardness(backdoor_vars)
        
        # Print certificate
        certificate.print_certificate()
        
        # Save to file
        filename = f"certificate_{structure}_{n_vars}vars.json"
        certificate.save_json(filename)
        
        certificates.append((description, certificate))
    
    # Summary
    print("\n" + "="*80)
    print("CERTIFICATION SUMMARY")
    print("="*80)
    
    for desc, cert in certificates:
        status_symbol = {
            CertificateStatus.DECOMPOSABLE: "‚úÖ",
            CertificateStatus.WEAKLY_DECOMPOSABLE: "üü°",
            CertificateStatus.UNDECOMPOSABLE: "‚ùå",
            CertificateStatus.INCONCLUSIVE: "‚ùì"
        }[cert.status]
        
        print(f"{status_symbol} {desc}")
        print(f"   Status: {cert.status.value.upper()}")
        print(f"   k* = {cert.optimal_separator_size} ({cert.normalized_separator:.1%} of N)")
        print(f"   Coupling: {cert.min_coupling_strength:.3f} (min), {cert.mean_coupling_strength:.3f} (mean)")
        print(f"   Poly-time: {cert.polynomial_time_solvable}, Confidence: {cert.confidence*100:.0f}%")
        print()


if __name__ == "__main__":
    print("="*80)
    print("SAT UNDECOMPOSABILITY CERTIFICATION")
    print("="*80)
    print()
    print("This module certifies whether a SAT problem is:")
    print("  ‚úÖ DECOMPOSABLE - Solvable in polynomial time with quantum")
    print("  üü° WEAKLY DECOMPOSABLE - Quantum helps but still exponential")
    print("  ‚ùå UNDECOMPOSABLE - Quantum-hard (no poly-time algorithm)")
    print()
    print("Method: Classical graph-theoretic proxies for quantum entanglement")
    print("Future: Replace with true quantum entanglement (QLTO-VQE + toqito)")
    print()
    
    test_certification()
